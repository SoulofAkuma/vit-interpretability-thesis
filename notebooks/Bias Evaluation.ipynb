{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import timm\n",
    "import tabulate\n",
    "import pyperclip\n",
    "import db_utils as dbu\n",
    "import torch.nn.functional as F\n",
    "\n",
    "%matplotlib inline \n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "device = 'cpu'# 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model_names = ['vit_base_patch16_224', \n",
    "               'vit_base_patch16_224_miil', \n",
    "               'vit_base_patch32_224', \n",
    "               'vit_large_patch16_224']\n",
    "pretty_model_names = {\n",
    "    'vit_base_patch16_224': 'ViT-B/16', \n",
    "    'vit_base_patch16_224_miil': 'ViT-B/16-MIIL', \n",
    "    'vit_base_patch32_224': 'ViT-B/32', \n",
    "    'vit_large_patch16_224': 'ViT-L/16'\n",
    "}\n",
    "models = {\n",
    "    model_name: timm.create_model(model_name, pretrained=True).eval().to(device)\n",
    "    for model_name in model_names\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "Make sure the `imagenet_val_evaluator.py` script has been executed. Fill in the path to the bias activations below here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_pl_resid_path = 'A:\\\\CVData\\\\ImageNet\\\\val_top_bias_pl_resid'\n",
    "bias_pl_vec_noise_path = 'A:\\\\CVData\\\\ImageNet\\\\val_top_bias_pl_vec_noise'\n",
    "bias_pl_all_path = 'A:\\\\CVData\\\\ImageNet\\\\val_top_bias_pl_all'\n",
    "db_path = 'imgnet_val_prelim.db'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Na√Øve Bias Addition to Value Vectors\n",
    "Here the bias is added to every extracted value vector. Then these vectors are projected with the MLP head and the most predictive vector is determined by identifying the vector with the highest class score. Based on the concept that for blocks where classes have their most predictive value vectors, the following holds true:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\t\\bm{t}_{\\text{cls}}^{(b^{v_c^*},\\text{MLP})} & \\approx \\bm{b}_V^{(b^{v_c^*},\\text{MLP})} + \\bm{v}_c^*.\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.extraction import extract_value_vectors, extract_value_biases\n",
    "from src.utils.model import embedding_projection\n",
    "from src.analyzers.vector_analyzer import most_predictive_ind_for_classes\n",
    "\n",
    "values = {\n",
    "    model_name: extract_value_vectors(models[model_name], device, stack=True)\n",
    "    for model_name in model_names\n",
    "}\n",
    "values_with_bias = {\n",
    "    model_name: extract_value_vectors(models[model_name], device, True, 1.0)\n",
    "    for model_name in model_names\n",
    "}\n",
    "projected_values = {\n",
    "    model_name: embedding_projection(models[model_name], values[model_name], device)\n",
    "    for model_name in model_names\n",
    "}\n",
    "projected_values_with_bias = {\n",
    "    model_name: embedding_projection(models[model_name], values_with_bias[model_name], device)\n",
    "    for model_name in model_names\n",
    "}\n",
    "most_predictive = {\n",
    "    model_name: most_predictive_ind_for_classes(projected_values[model_name], device)\n",
    "    for model_name in model_names\n",
    "}\n",
    "most_predictive_with_bias = {\n",
    "    model_name: most_predictive_ind_for_classes(projected_values_with_bias[model_name], device)\n",
    "    for model_name in model_names\n",
    "}\n",
    "\n",
    "avg_cls_score = {\n",
    "    model_name: projected_values[model_name][most_predictive[model_name][0,:], \n",
    "                                             most_predictive[model_name][1,:], \n",
    "                                             most_predictive[model_name][2,:]].mean().item()\n",
    "    for model_name in model_names\n",
    "}\n",
    "avg_cls_score_with_bias = {\n",
    "    model_name: projected_values_with_bias[model_name][most_predictive[model_name][0,:], \n",
    "                                                       most_predictive[model_name][1,:], \n",
    "                                                       most_predictive[model_name][2,:]].mean().item()\n",
    "    for model_name in model_names\n",
    "}\n",
    "avg_bias_predictive_cls_score_with_bias = {\n",
    "    model_name: projected_values_with_bias[model_name][most_predictive_with_bias[model_name][0,:], \n",
    "                                                       most_predictive_with_bias[model_name][1,:], \n",
    "                                                       most_predictive_with_bias[model_name][2,:]].mean().item()\n",
    "    for model_name in model_names\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_cls_score_val = [row[1] for row in dbu.sort_like(\n",
    "    model_names, \n",
    "    dbu.select(db_path, 'select pred_model, avg(top_0_score) from predictions group by pred_model'))]\n",
    "\n",
    "predictive_vector_weights = dbu.select(\n",
    "    db_path, 'select pred_model, num_idx, avg(top_0_cls_token_act) from vec_activations '\n",
    "    'group by pred_model, num_idx order by pred_model, num_idx')\n",
    "predictive_vector_weights = dbu.group_by_tensor(predictive_vector_weights, 0, 2, True)\n",
    "\n",
    "cls_scores_around_most_pred = dbu.select(\n",
    "    db_path, 'select pred_model, num_idx, avg(before_most_predictive_pred), '\n",
    "    'avg(after_most_predictive_pred), avg(cls_score_bias_pl_all_pred) from vec_activations group by '\n",
    "    'pred_model, num_idx order by pred_model, num_idx'\n",
    ")\n",
    "score_before_most_pred = dbu.group_by_tensor(cls_scores_around_most_pred, 0, 2, True)\n",
    "score_after_most_pred = dbu.group_by_tensor(cls_scores_around_most_pred, 0, 3, True)\n",
    "score_bias_pl_all_pred = dbu.group_by_tensor(cls_scores_around_most_pred, 0, 4, True)\n",
    "\n",
    "avg_cls_score_with_bias_weighted = {}\n",
    "avg_percentage_score_with_bias_weighted = {}\n",
    "value_biases = {\n",
    "        model_name: extract_value_biases(models[model_name], device, True)\n",
    "        for model_name in model_names\n",
    "}\n",
    "\n",
    "for model_name in model_names:\n",
    "    most_pred_values = values[model_name][most_predictive[model_name][0,:], \n",
    "                                          most_predictive[model_name][1,:]]\n",
    "    most_pred_values *= F.gelu(predictive_vector_weights[model_name].to(device)[:, None])\n",
    "    most_pred_biases = value_biases[model_name][most_predictive[model_name][0,:]]\n",
    "    cls_score_with_bias_weighted = torch.diagonal(embedding_projection(\n",
    "            models[model_name], most_pred_values + most_pred_biases\n",
    "    ))\n",
    "    avg_percentage_score_with_bias_weighted[model_name] = (cls_score_with_bias_weighted / \n",
    "        (score_after_most_pred[model_name] - score_before_most_pred[model_name])).mean().item()\n",
    "    avg_cls_score_with_bias_weighted[model_name] = cls_score_with_bias_weighted.mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| Average of                                                                                                   |   ViT-B/16 |   ViT-B/16-MIIL |   ViT-B/32 |   ViT-L/16 |\n",
       "|--------------------------------------------------------------------------------------------------------------|------------|-----------------|------------|------------|\n",
       "| $(\\bm{v}_c^* E)_c$                                                                                           |      9.150 |          10.477 |     10.680 |      9.837 |\n",
       "| $((\\bm{b}_V^{(b^{v_c^*},\\text{MLP})} + \\bm{v}_c^*) E)_c$                                                     |      0.361 |           4.180 |      1.054 |      1.389 |\n",
       "| $(\\bm{t}_{\\text{cls}}^{\\text{pred}} E)_c$                                                                    |     13.676 |          10.825 |     13.916 |     13.880 |\n",
       "| $((\\bm{b}_V^{(b^{v_c^*},\\text{MLP})} + \\text{GELU}\\left(w^{v^*_c}_{\\text{cls}}\\right)\\bm{v}_c^*) \\cdot E)_c$ |      1.068 |           2.759 |      2.346 |      2.047 |\n",
       "| percentage                                                                                                   |      0.713 |           0.935 |      0.786 |      0.675 |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display_markdown\n",
    "\n",
    "tbl_headers = ['Average of'] + [pretty_model_names[model_name] for model_name in model_names]\n",
    "bias_comparison = [['$(\\\\bm{v}_c^* E)_c$'] + [avg_cls_score[model_name] for model_name in model_names], \n",
    "                     ['$((\\\\bm{b}_V^{(b^{v_c^*},\\\\text{MLP})} + \\\\bm{v}_c^*) E)_c$'] + \n",
    "                     [avg_cls_score_with_bias[model_name] for model_name in model_names],\n",
    "                     ['$(\\\\bm{t}_{\\\\text{cls}}^{\\\\text{pred}} E)_c$'] + avg_cls_score_val,\n",
    "                     ['$((\\\\bm{b}_V^{(b^{v_c^*},\\\\text{MLP})} + \\\\text{GELU}\\\\left(w^{v^*_c}_{\\\\text'  \n",
    "                      '{cls}}\\\\right)\\\\bm{v}_c^*) \\\\cdot E)_c$'] + \n",
    "                     [avg_cls_score_with_bias_weighted[model_name] for model_name in model_names],\n",
    "                     ['percentage'] + \n",
    "                     [avg_percentage_score_with_bias_weighted[model_name] for model_name in model_names]]\n",
    "\n",
    "display_markdown(\n",
    "    tabulate.tabulate(bias_comparison, tbl_headers, floatfmt='.3f', tablefmt='github'), raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['path',\n",
       " 'pred_model',\n",
       " 'imagenet_id',\n",
       " 'num_idx',\n",
       " 'name',\n",
       " 'top_0_cls_token_act',\n",
       " 'top_1_cls_token_act',\n",
       " 'top_2_cls_token_act',\n",
       " 'top_3_cls_token_act',\n",
       " 'top_4_cls_token_act',\n",
       " 'top_5_cls_token_act',\n",
       " 'top_6_cls_token_act',\n",
       " 'top_7_cls_token_act',\n",
       " 'top_8_cls_token_act',\n",
       " 'top_9_cls_token_act',\n",
       " 'top_0_img_token_avg_act',\n",
       " 'top_1_img_token_avg_act',\n",
       " 'top_2_img_token_avg_act',\n",
       " 'top_3_img_token_avg_act',\n",
       " 'top_4_img_token_avg_act',\n",
       " 'top_5_img_token_avg_act',\n",
       " 'top_6_img_token_avg_act',\n",
       " 'top_7_img_token_avg_act',\n",
       " 'top_8_img_token_avg_act',\n",
       " 'top_9_img_token_avg_act',\n",
       " 'top_0_block_ind',\n",
       " 'top_1_block_ind',\n",
       " 'top_2_block_ind',\n",
       " 'top_3_block_ind',\n",
       " 'top_4_block_ind',\n",
       " 'top_5_block_ind',\n",
       " 'top_6_block_ind',\n",
       " 'top_7_block_ind',\n",
       " 'top_8_block_ind',\n",
       " 'top_9_block_ind',\n",
       " 'top_0_vec_ind',\n",
       " 'top_1_vec_ind',\n",
       " 'top_2_vec_ind',\n",
       " 'top_3_vec_ind',\n",
       " 'top_4_vec_ind',\n",
       " 'top_5_vec_ind',\n",
       " 'top_6_vec_ind',\n",
       " 'top_7_vec_ind',\n",
       " 'top_8_vec_ind',\n",
       " 'top_9_vec_ind',\n",
       " 'top_0_max_cls_token_act',\n",
       " 'top_1_max_cls_token_act',\n",
       " 'top_2_max_cls_token_act',\n",
       " 'top_3_max_cls_token_act',\n",
       " 'top_4_max_cls_token_act',\n",
       " 'top_5_max_cls_token_act',\n",
       " 'top_6_max_cls_token_act',\n",
       " 'top_7_max_cls_token_act',\n",
       " 'top_8_max_cls_token_act',\n",
       " 'top_9_max_cls_token_act',\n",
       " 'top_0_max_cls_act_block_ind',\n",
       " 'top_1_max_cls_act_block_ind',\n",
       " 'top_2_max_cls_act_block_ind',\n",
       " 'top_3_max_cls_act_block_ind',\n",
       " 'top_4_max_cls_act_block_ind',\n",
       " 'top_5_max_cls_act_block_ind',\n",
       " 'top_6_max_cls_act_block_ind',\n",
       " 'top_7_max_cls_act_block_ind',\n",
       " 'top_8_max_cls_act_block_ind',\n",
       " 'top_9_max_cls_act_block_ind',\n",
       " 'top_0_max_cls_act_vec_ind',\n",
       " 'top_1_max_cls_act_vec_ind',\n",
       " 'top_2_max_cls_act_vec_ind',\n",
       " 'top_3_max_cls_act_vec_ind',\n",
       " 'top_4_max_cls_act_vec_ind',\n",
       " 'top_5_max_cls_act_vec_ind',\n",
       " 'top_6_max_cls_act_vec_ind',\n",
       " 'top_7_max_cls_act_vec_ind',\n",
       " 'top_8_max_cls_act_vec_ind',\n",
       " 'top_9_max_cls_act_vec_ind',\n",
       " 'top_0_max_img_token_avg_act',\n",
       " 'top_1_max_img_token_avg_act',\n",
       " 'top_2_max_img_token_avg_act',\n",
       " 'top_3_max_img_token_avg_act',\n",
       " 'top_4_max_img_token_avg_act',\n",
       " 'top_5_max_img_token_avg_act',\n",
       " 'top_6_max_img_token_avg_act',\n",
       " 'top_7_max_img_token_avg_act',\n",
       " 'top_8_max_img_token_avg_act',\n",
       " 'top_9_max_img_token_avg_act',\n",
       " 'top_0_max_img_avg_act_block_ind',\n",
       " 'top_1_max_img_avg_act_block_ind',\n",
       " 'top_2_max_img_avg_act_block_ind',\n",
       " 'top_3_max_img_avg_act_block_ind',\n",
       " 'top_4_max_img_avg_act_block_ind',\n",
       " 'top_5_max_img_avg_act_block_ind',\n",
       " 'top_6_max_img_avg_act_block_ind',\n",
       " 'top_7_max_img_avg_act_block_ind',\n",
       " 'top_8_max_img_avg_act_block_ind',\n",
       " 'top_9_max_img_avg_act_block_ind',\n",
       " 'top_0_max_img_avg_act_vec_ind',\n",
       " 'top_1_max_img_avg_act_vec_ind',\n",
       " 'top_2_max_img_avg_act_vec_ind',\n",
       " 'top_3_max_img_avg_act_vec_ind',\n",
       " 'top_4_max_img_avg_act_vec_ind',\n",
       " 'top_5_max_img_avg_act_vec_ind',\n",
       " 'top_6_max_img_avg_act_vec_ind',\n",
       " 'top_7_max_img_avg_act_vec_ind',\n",
       " 'top_8_max_img_avg_act_vec_ind',\n",
       " 'top_9_max_img_avg_act_vec_ind',\n",
       " 'top_bias_l2',\n",
       " 'top_bias_pl_res_l2',\n",
       " 'resid_l2',\n",
       " 'top_bias_pl_vec_noise_l2',\n",
       " 'vec_noise_l2',\n",
       " 'top_bias_pl_all_l2',\n",
       " 'all_l2',\n",
       " 'path_bias_pl_res_pred',\n",
       " 'path_bias_pl_vec_noise_pred',\n",
       " 'path_bias_pl_all_pred',\n",
       " 'mean_bias_pl_res_pred',\n",
       " 'mean_bias_pl_vec_noise_pred',\n",
       " 'mean_bias_pl_all_pred',\n",
       " 'std_bias_pl_res_pred',\n",
       " 'std_bias_pl_vec_noise_pred',\n",
       " 'std_bias_pl_all_pred',\n",
       " 'max_bias_pl_res_pred',\n",
       " 'max_bias_pl_vec_noise_pred',\n",
       " 'max_bias_pl_all_pred',\n",
       " 'mean_top_bias_pred',\n",
       " 'std_top_bias_pred',\n",
       " 'max_top_bias_pred',\n",
       " 'mean_resid_pred',\n",
       " 'std_resid_pred',\n",
       " 'max_resid_pred',\n",
       " 'mean_vec_noise_pred',\n",
       " 'std_vec_noise_pred',\n",
       " 'max_vec_noise_pred',\n",
       " 'mean_all_pred',\n",
       " 'std_all_pred',\n",
       " 'max_all_pred',\n",
       " 'cls_score_bias_pl_res_pred',\n",
       " 'cls_score_bias_pl_vec_noise_pred',\n",
       " 'cls_score_bias_pl_all_pred',\n",
       " 'cls_score_top_bias_pred',\n",
       " 'cls_score_resid_pred',\n",
       " 'cls_score_vec_noise_pred',\n",
       " 'cls_score_all_pred',\n",
       " 'before_most_predictive_pred',\n",
       " 'after_most_predictive_pred']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbu.get_column_names(db_path, 'vec_activations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictive_vector_weights = dbu.select(\n",
    "    db_path, 'select pred_model, num_idx, avg(top_0_cls_token_act) from vec_activations '\n",
    "    'group by pred_model, num_idx order by pred_model, num_idx')\n",
    "predictive_vector_weights = dbu.group_by_tensor(predictive_vector_weights, 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('vit_base_patch16_224',\n",
       "  1.1954224396071833,\n",
       "  4.127169065102373,\n",
       "  2.9059458256638515),\n",
       " ('vit_base_patch16_224_miil',\n",
       "  4.737318438119581,\n",
       "  7.441784518307187,\n",
       "  6.82038210035231),\n",
       " ('vit_base_patch32_224',\n",
       "  1.1713416013254738,\n",
       "  3.0311404356388447,\n",
       "  2.4313932356904635),\n",
       " ('vit_large_patch16_224',\n",
       "  4.11039840854872,\n",
       "  6.764502003012034,\n",
       "  5.352589148541773)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbu.select(db_path, 'select pred_model, avg(before_most_predictive_pred), avg(after_most_predictive_pred),'\n",
    "           ' avg(cls_score_all_pred) from vec_activations group by pred_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionTransformer(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "    (norm): Identity()\n",
       "  )\n",
       "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "  (norm_pre): Identity()\n",
       "  (blocks): Sequential(\n",
       "    (0): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (1): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (2): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (3): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (4): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (5): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (6): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (7): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (8): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (9): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (10): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (11): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): Identity()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): Identity()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "  (fc_norm): Identity()\n",
       "  (head): Linear(in_features=768, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[model_names[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vit-interpretability-thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
