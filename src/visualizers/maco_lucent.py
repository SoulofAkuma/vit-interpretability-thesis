# adapted from the PyTorch MACO implementation https://github.com/serre-lab/Horama 
from src.utils.imagenet import get_maco_magnitudes
import torch
from typing import Tuple, Union, Callable, List, Optional
import torch.nn as nn
from src.utils.tensor import standardize, recorrelate_colors, clip_quantile, normalize
from torchvision.ops import roi_align
from lucent.optvis.objectives import handle_batch, wrap_objective
from timm.models.vision_transformer import VisionTransformer
import numpy as np
from src.utils.extraction import extract_value_vectors
from src.utils.model import embedding_projection
from src.utils.imagenet import get_index_for_imagenet_id
from src.analyzers.vector_analyzer import most_predictive_ind_for_classes
from lucent.optvis import render

def init_maco_buffer(image_shape: Tuple[int, int], 
                     std_deviation: float=1.0, 
                     device: Optional[str]=None) -> Tuple[torch.Tensor, torch.Tensor]:
    """Initialize a random phase and the pre-calculated maco imagenet magnitudes

    Args:
        image_shape (Tuple[int, int]): the shape of the image
        std_deviation (float, optional): The standard deviation of the phase. Defaults to 1.0.
        device (Optional[str], optional): The device to move phase and magnitude to. Defaults to None.

    Returns:
        Tuple[torch.Tensor, torch.Tensor]: A tuple that contains the magnitudes at index 0 and
        the random phase at index 1 
    """

    device = device or 'cuda' if torch.cuda.is_available() else 'cpu'

    # initialize the maco buffer with a random phase and a magnitude template
    spectrum_shape = (image_shape[0], image_shape[1] // 2 + 1)

    # generate random phase
    random_phase = torch.randn(3, *spectrum_shape, dtype=torch.float32) * std_deviation

    # get maco imgnet magnitudes
    magnitude = get_maco_magnitudes(spectrum_shape)

    if device is not None:
        random_phase = random_phase.to(device)
        magnitude = magnitude.to(device)

    random_phase.requires_grad = True

    return magnitude, random_phase

def maco_lucent_param_f(image_size: int, values_range: Tuple[float, float]=(-2.5, 2.5),
                        device: Optional[str]=None, phase_std_deviation: float=1.0) \
                            -> Callable[[], Tuple[List[nn.Parameter], Callable[[], torch.Tensor]]]:
    """The param_f function to use the maco feature visualization method with the lucent framework.

    Args:
        image_size (int): The size of pixels per size of the square image.
        values_range (Tuple[float, float], optional): _description_. Defaults to (-2.5, 2.5).
        device (Optional[str], optional): _description_. Defaults to None.
        phase_std_deviation (float, optional): _description_. Defaults to 1.0.

    Returns:
        Callable[[], Tuple[List[nn.Parameter], Callable[[], torch.Tensor]]]: This return value can be \
            used as the param_f parameter in the lucent framework. A function that can be called to \
            return the parameters and another callback function that generates an image based on the \
            internal image parameters.
    """

    image_shape = (image_size, image_size)

    device = device or 'cuda' if torch.cuda.is_available() else 'cpu'

    magnitude, phase = init_maco_buffer(image_shape, phase_std_deviation, device)

    def image_generator():
        standardized_phase = standardize(phase)
        complex_spectrum = torch.complex(torch.cos(standardized_phase) * magnitude,
                                        torch.sin(standardized_phase) * magnitude)

        # transform to spatial domain and standardize
        spatial_image = torch.fft.irfft2(complex_spectrum)
        spatial_image = standardize(spatial_image)

        # recorrelate colors and adjust value range
        color_recorrelated_image = recorrelate_colors(spatial_image, device)
        final_image = torch.sigmoid(
            color_recorrelated_image) * (values_range[1] - values_range[0]) + values_range[0]
        
        final_image.retain_grad()

        return final_image

    return lambda: ([phase], image_generator)

def image_posttasks(image: torch.Tensor, alpha: Optional[torch.Tensor], 
                    quantile_to_clip_img: float =0.01, 
                    quantile_top_clip_alpha: float=0.8) -> torch.Tensor:
    """Apply to the image generated with maco in lucent before attempting to show or store the image
    as maco allows negative intensity values during optimization and clips outlier intensities.

    Args:
        image (torch.Tensor): The generated image of shape (3, H, W)
        alpha (Optional[torch.Tensor]): The alpha channel generated by maco in lucent.
        quantile_to_clip (float): The lower quantile to clip to and 1-quantile_to_clip as the upper \
            boundary to clip to. Defaults to 0.01.
        quantile_top_clip_alpha (float): The top quantile to clip away from the alpha channel. \
            Defaults to 0.8.

    Returns:
        torch.Tensor: The final image of shape (3 x H x W) if no alpha channel was provided \
            and (4 x H x W) if an alpha channel was provided.
    """
    image = image.detach().cpu().permute(1,2,0)
    image = clip_quantile(image, quantile_to_clip_img)
    image = normalize(image)

    # mean of alpha across channels, clipping, and normalization
    alpha = alpha.detach().cpu().permute(1,2,0)
    alpha = torch.mean(alpha, dim=-1, keepdim=True)
    alpha = torch.clip(alpha, max=torch.quantile(alpha, quantile_top_clip_alpha))
    alpha = alpha / alpha.max()

    # overlay alpha mask on the image
    return torch.concatenate([image, alpha], dim=-1)

def maco_post_grad_f(image_size: int, device: Optional[str]) \
        -> Tuple[Callable[[], torch.Tensor],  Callable[[torch.Tensor, torch.Tensor], None]]:
    """Get an alpha retriever function and a post_grad_f function for the lucent framework.

    Args:
        image_size (int): The size of the image that is being generated.
        device (Optional[str]): The device the image is stored on. Defaults to None

    Returns:
        Tuple[Callable[[], torch.Tensor],  Callable[[torch.Tensor]]]: The first callable in the tuple \
        returns the accumulated alpha score. The second can be passed to the lucent-maco visualization \
        to accumulate the alpha.
    """

    device = device or 'cuda' if torch.cuda.is_available() else 'cpu'

    accumulated_alpha = torch.zeros(3, image_size, image_size).to(device)

    def accumulator(images, _):
        nonlocal accumulated_alpha
        accumulated_alpha += torch.abs(images.grad)

    return (lambda: accumulated_alpha), accumulator

def maco_transforms(nr_of_crops_per_iteration: int, box_size: Tuple[int, int], 
                    noise_level: float, model_img_size: int, image_size: int, 
                    device: Optional[str]=None) -> List[Callable[[torch.Tensor], torch.Tensor]]:
    """The list of transforms that the maco optimization uses for the lucent framework.

    Args:
        nr_of_crops_per_iteration (int): The number of times the image is randomly cropped per iteration
        box_size (Tuple[int, int]): The size of the crops from the center.
        noise_level (float): The amount of noise applied to the image.
        model_img_size (int): The image size the model requires.
        image_size (int): The size of the image that will be generated
        device (Optional[str], optional): The device the images are on. Defaults to None.

    Returns:
        List[Callable[[torch.Tensor], torch.Tensor]]: A list of transforms to pass to the \
            lucent framework.
    """
    def transforms(image):
        x0 = 0.5 + torch.randn((nr_of_crops_per_iteration,), device=device) * 0.15
        y0 = 0.5 + torch.randn((nr_of_crops_per_iteration,), device=device) * 0.15
        delta_x = torch.rand((nr_of_crops_per_iteration,),
                            device=device) * (box_size[1] - box_size[0]) + box_size[1]
        delta_y = delta_x
        boxes = torch.stack([torch.zeros((nr_of_crops_per_iteration,), device=device),
                            x0 - delta_x * 0.5,
                            y0 - delta_y * 0.5,
                            x0 + delta_x * 0.5,
                            y0 + delta_y * 0.5], dim=1) * image_size
        
        cropped_and_resized_images = roi_align(image.unsqueeze(
        0), boxes, output_size=(model_img_size, model_img_size)).squeeze(0)

        cropped_and_resized_images.add_(torch.randn_like(cropped_and_resized_images) * noise_level)
        cropped_and_resized_images.add_(
            (torch.rand_like(cropped_and_resized_images) - 0.5) * noise_level)
        
        return cropped_and_resized_images
    
    return [transforms]


def maco_optimizer_generator(learning_rate: float=1.0) -> \
        Callable[[List[nn.Parameter]], torch.optim.Optimizer]:
    """Get a lucent compatible optimizer generator function with a specified learning rate
    that creates the optimizer used by maco.

    Args:
        learning_rate (float, optional): The learning rate of the optimizer. Defaults to 1.0.
    """

    def generator(params):
        return torch.optim.NAdam(params, lr=learning_rate)
    return generator

@wrap_objective()
def key_neuron_objective(block: int, column: int, batch: int=None, before_nonlinear: bool=True, 
                         token_boundaries: Tuple[Optional[int], Optional[int]]=(None, None),
                         use_cosine_similarity: bool=False) \
                            -> Callable[[Callable[[str], torch.Tensor]], torch.Tensor]:
    """Get a lucent and maco compatible objective to optimize towards the
    value of a key vector. Ideally you pass the row index of a 
    value vector that most predicts a class here, to optimize via the
    weights for this value vector

    Args:
        block (int): The block the key neuron/column vector is on
        column (int): The index of the column vector
        batch (int, optional): The batch size (how many images to optimize). Defaults to None.
        before_nonlinear (bool, optional): True if the activation of the first fully connected
        layer should be used and False if the activations should be used after applying the nonlinear
        activation function. Using the value after the nonlinearity degrades most, but sometimes
        leads to extremely good results, while using the activations without nonlinearity guarantees
        meaningful results that are of a good quality. Defaults to True.
        token_boundaries (Tuple[int, int], optional): The range of tokens to consider. Defaults to
        (None, None), meaning all tokens.
        use_cosine_similarity (bool, optional): True if the cosine similarity between. \
            Not currently implemented

    Returns:
        Callable[[Callable[[str], torch.Tensor]], torch.Tensor]: A lucent compatible objective to \
            maximize a transformer neuron activation
    """
    layer_descriptor = f"blocks_{block}_mlp_{'fc1' if before_nonlinear else 'act'}"
    def inner(model):
        layer = model(layer_descriptor)
        
        return -layer[:, token_boundaries[0]:token_boundaries[1], column].mean()
    return inner

def generate_most_stimulative_for_imgnet_id(model: VisionTransformer, 
                                            imagenet_id: Union[str, List[str]],
                                            device: Optional[str]=None,
                                            most_predictive_inds: Optional[torch.Tensor]=None,
                                            iterations: Optional[List[int]]=None,
                                            img_size: int=1280, model_img_size: int=224,
                                            keys_before_nonlinear: bool=True,
                                            optimize_cls_token_only: bool=False,
                                            image_value_range: Optional[Tuple[int, int]]=(-2.5, 2.5),
                                            phase_std_deviation: int=1,
                                            learning_rate: float=1.0,
                                            nr_of_crops_per_iteration: int=6,
                                            box_size: Optional[Tuple[int, int]]=(0.20, 0.25),
                                            noise_level_per_iteration: float=0.05,
                                            apply_alpha: bool=True,
                                            quantile_to_clip_img: float =0.01, 
                                            quantile_top_clip_alpha: float=0.8
                                            ) -> torch.Tensor:
    """Generate the most stimulative image for a top value vector of an ImageNet class using maco, 
    maximizing the corresponding key vector.

    Args:
        model (VisionTransformer): The model to generate the image(s) for.
        imagenet_id (Union[str, List[str]]): The imagenet id of the class to generate the \
            image for. Optionally a list to generate for multiple classes at once
        device (str, optional): The device to execute calculations on. Defaults to None.
        most_predictive_inds (torch.Tensor, optional): The most predictive value vectors for each of the ImageNet-1k classes, if they have already been computed. Defaults to None.
        iterations (List[int], optional): The number of iterations at which you want to save the image. Should be in increasing order and the last element should be the number of iterations in total. Defaults to [500].
        img_size (int, optional): The image size of the image to generate. Defaults to 128.
        model_img_size (int, optional): The image size the model expects. Defaults to 224.
        keys_before_nonlinear (bool, optional): For a detailed documentation see key_neuron_objective function documentation. Defaults to True.
        optimize_cls_token_only (bool, optional): Set to true if only the cls token should contribute to the loss to optimize the image with and only the image tokens should contribute to the diversity objective. Defaults to False.
        nr_of_crops_per_iteration (int): The number of times the image is randomly cropped per iteration
        box_size (Tuple[int, int]): The size of the crops from the center.
        noise_level_per_iteration (float): The amount of noise applied to the image.
        learning_rate (float, optional): The learning rate of the optimizer. Defaults to 1.0.
        image_value_range (Tuple[float, float], optional): _description_. Defaults to (-2.5, 2.5).
        device (Optional[str], optional): _description_. Defaults to None.
        phase_std_deviation (float, optional): _description_. Defaults to 1.0.
        quantile_to_clip (float, optional ): The lower quantile to clip to and 1-quantile_to_clip as \
            the upper boundary to clip to. Defaults to 0.01.
        quantile_top_clip_alpha (float, optional): The top quantile to clip away from the alpha \ 
            channel. Defaults to 0.8.
        apply_alpha (boolean, optional): True if the alpha channel should be applied to the image in the end. Defaults to True.

    Returns:
        torch.Tensor: The optimized image.
    """

    if type(imagenet_id) is not list:
        imagenet_id = [imagenet_id]

    device = device or torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    iterations = iterations or [1000]

    if most_predictive_inds is None:
        values = extract_value_vectors(model, device)
        emb_values = embedding_projection(model, values, device)
        most_predictive_inds = most_predictive_ind_for_classes(emb_values, device)

    cls_indices = torch.tensor(list(map(get_index_for_imagenet_id, imagenet_id)))
    mul = 1 / len(imagenet_id)

    blocks, inds, _ = most_predictive_inds[:,cls_indices].tolist()

    neuron_objective = key_neuron_objective(blocks[0], inds[0], 
                                            before_nonlinear=keys_before_nonlinear,
                                            token_boundaries=(0, 1) 
                                            if optimize_cls_token_only else (None, None)) * -mul
    
    for i in range(1, len(imagenet_id)):
        neuron_objective += mul * key_neuron_objective(blocks[i], inds[i],
                                                       before_nonlinear=keys_before_nonlinear,
                                                       token_boundaries=(0, 1)
                                                       if optimize_cls_token_only else 
                                                       (None, None))
    
    # neuron_objective = class_objective(388)

    param_f = maco_lucent_param_f(img_size, image_value_range, device, phase_std_deviation)
    optimizer = maco_optimizer_generator(learning_rate)
    alpha_retriever, post_grad_f = maco_post_grad_f(img_size, device)
    transforms = maco_transforms(nr_of_crops_per_iteration, box_size, noise_level_per_iteration,
                                 model_img_size, img_size, device)
    
    result_img = render.render_vis(model, neuron_objective, param_f, optimizer, transforms, iterations,
                                   preprocess=False, show_image=False, show_inline=False,
                                   fixed_image_size=model_img_size, device=device, 
                                   post_grad_f=post_grad_f, skip_size_transform=True,
                                   images_as_tensor=True)
    alpha = alpha_retriever()

    return image_posttasks(result_img[0], alpha if apply_alpha else None, quantile_to_clip_img,
                           quantile_top_clip_alpha)

@wrap_objective()
def class_objective(cls_index: int):
    def inner(model):
        return -torch.mean(model('labels')[:,cls_index])
    return inner